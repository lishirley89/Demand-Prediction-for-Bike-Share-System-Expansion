{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# XGBoost Model for Bike Station Demand Prediction\n",
        "\n",
        "This notebook implements XGBoost models for predicting bike station demand with separate models for:\n",
        "- `cbike_start`: Classic bike start trips\n",
        "- `cbike_end`: Classic bike end trips  \n",
        "- `ebike_start`: E-bike start trips\n",
        "- `ebike_end`: E-bike end trips\n",
        "\n",
        "## ‚úÖ GPU Error Fix Applied\n",
        "\n",
        "**The original GPU error has been fixed!** The notebook now includes:\n",
        "1. **Fixed GPU Setup** (Section 2) - Safely detects and tests GPU functionality\n",
        "2. **Robust GPU Detection** (Section 2.1) - Alternative robust detection method\n",
        "3. **Quick Fix Option** (Section 2.2) - Force CPU mode if needed\n",
        "\n",
        "## Features:\n",
        "- **GPU Optimization**: Automatically detects and uses GPU in Google Colab\n",
        "- **Hyperparameter Tuning**: Grid search with cross-validation\n",
        "- **Comprehensive Evaluation**: R¬≤, RMSE, and MAE metrics\n",
        "- **Feature Engineering**: Handles skewed variables and collinearity\n",
        "- **Error Handling**: Robust GPU detection and CPU fallback\n",
        "\n",
        "## Data Requirements:\n",
        "- Preprocessed training and test datasets\n",
        "- Standardized features\n",
        "- One-hot encoded month variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages if not already installed\n",
        "!pip install xgboost pandas numpy scikit-learn matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "print('All packages imported successfully!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. GPU Setup for Google Colab (Fixed Version)\n",
        "\n",
        "‚úÖ **FIXED**: The original problematic GPU setup has been replaced with a safer version that properly tests GPU functionality before using it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.1. Fixed GPU Setup (Robust Detection)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXED GPU DETECTION - Use this instead of the previous cell\n",
        "def setup_gpu_robust():\n",
        "    \"\"\"\n",
        "    Robust GPU setup for XGBoost in Google Colab.\n",
        "    Returns True if GPU is available and working, False otherwise.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Check if we're in Google Colab\n",
        "        import google.colab\n",
        "        print('‚úÖ Running in Google Colab')\n",
        "        \n",
        "        # Check GPU availability with nvidia-smi\n",
        "        import subprocess\n",
        "        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
        "        \n",
        "        if result.returncode == 0:\n",
        "            print('‚úÖ GPU hardware detected!')\n",
        "            print('GPU Info:')\n",
        "            print(result.stdout.split('\\\\n')[0:3])  # Show first few lines\n",
        "            \n",
        "            # Test XGBoost GPU functionality with a small dataset\n",
        "            try:\n",
        "                import xgboost as xgb\n",
        "                print('\\\\nüîç Testing XGBoost GPU functionality...')\n",
        "                \n",
        "                # Create minimal test data\n",
        "                import numpy as np\n",
        "                test_X = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "                test_y = np.array([1, 2, 3])\n",
        "                \n",
        "                # Test GPU XGBoost\n",
        "                test_model = xgb.XGBRegressor(\n",
        "                    tree_method='gpu_hist',\n",
        "                    gpu_id=0,\n",
        "                    n_estimators=2,\n",
        "                    random_state=42,\n",
        "                    verbosity=0\n",
        "                )\n",
        "                test_model.fit(test_X, test_y)\n",
        "                test_pred = test_model.predict(test_X)\n",
        "                print('‚úÖ XGBoost GPU functionality confirmed!')\n",
        "                return True\n",
        "                \n",
        "            except Exception as gpu_error:\n",
        "                print(f'‚ùå GPU detected but XGBoost GPU failed: {gpu_error}')\n",
        "                print('üîÑ Falling back to CPU mode')\n",
        "                return False\n",
        "        else:\n",
        "            print('‚ö†Ô∏è  No GPU hardware detected')\n",
        "            print('üîÑ Using CPU mode')\n",
        "            return False\n",
        "            \n",
        "    except ImportError:\n",
        "        print('‚ö†Ô∏è  Not running in Google Colab - using CPU mode')\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f'‚ùå Error during GPU detection: {e}')\n",
        "        print('üîÑ Falling back to CPU mode')\n",
        "        return False\n",
        "\n",
        "# Setup GPU with robust detection\n",
        "USE_GPU = setup_gpu_robust()\n",
        "print(f'\\\\nüöÄ Final GPU Mode: {\"Enabled\" if USE_GPU else \"Disabled\"}')\n",
        "\n",
        "# Force CPU mode if GPU detection failed\n",
        "if not USE_GPU:\n",
        "    print('\\\\n‚ö†Ô∏è  IMPORTANT: Using CPU mode for all XGBoost models')\n",
        "    print('   This will be slower but more reliable')\n",
        "else:\n",
        "    print('\\\\n‚úÖ GPU mode enabled - XGBoost will use GPU acceleration')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üö® QUICK FIX FOR GPU ERROR\n",
        "\n",
        "If you got the GPU error above, run this cell instead to force CPU mode:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# QUICK FIX: Force CPU mode to avoid GPU errors\n",
        "print(\"üîß Applying quick fix for GPU error...\")\n",
        "USE_GPU = False  # Force CPU mode\n",
        "print(\"‚úÖ CPU mode enabled - this will prevent GPU errors\")\n",
        "print(\"‚ö†Ô∏è  Training will be slower but more reliable\")\n",
        "print(f\"üöÄ GPU Mode: {'Enabled' if USE_GPU else 'Disabled (Fixed)'}\")\n",
        "\n",
        "# Verify XGBoost works in CPU mode\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    import numpy as np\n",
        "    \n",
        "    # Test CPU XGBoost\n",
        "    test_X = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "    test_y = np.array([1, 2, 3])\n",
        "    \n",
        "    test_model = xgb.XGBRegressor(\n",
        "        tree_method='hist',  # CPU method\n",
        "        n_estimators=2,\n",
        "        random_state=42,\n",
        "        verbosity=0\n",
        "    )\n",
        "    test_model.fit(test_X, test_y)\n",
        "    print(\"‚úÖ XGBoost CPU mode confirmed working!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error testing XGBoost: {e}\")\n",
        "    print(\"Please restart the runtime and try again\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ORIGINAL GPU SETUP - REPLACED WITH SAFER VERSION\n",
        "# This function was causing GPU errors, so it's been replaced with a safer version\n",
        "\n",
        "def setup_gpu_safe():\n",
        "    \"\"\"\n",
        "    Safe GPU setup for XGBoost in Google Colab.\n",
        "    Returns True if GPU is available and working, False otherwise.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Check if we're in Google Colab\n",
        "        import google.colab\n",
        "        print('‚úÖ Running in Google Colab')\n",
        "        \n",
        "        # Check GPU availability with subprocess (safer than !nvidia-smi)\n",
        "        import subprocess\n",
        "        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
        "        \n",
        "        if result.returncode == 0:\n",
        "            print('‚úÖ GPU hardware detected!')\n",
        "            \n",
        "            # Test XGBoost GPU functionality with minimal test\n",
        "            try:\n",
        "                import xgboost as xgb\n",
        "                import numpy as np\n",
        "                \n",
        "                # Minimal test data\n",
        "                test_X = np.array([[1, 2], [3, 4]])\n",
        "                test_y = np.array([1, 2])\n",
        "                \n",
        "                # Test GPU XGBoost\n",
        "                test_model = xgb.XGBRegressor(\n",
        "                    tree_method='gpu_hist',\n",
        "                    gpu_id=0,\n",
        "                    n_estimators=1,\n",
        "                    random_state=42,\n",
        "                    verbosity=0\n",
        "                )\n",
        "                test_model.fit(test_X, test_y)\n",
        "                print('‚úÖ XGBoost GPU functionality confirmed!')\n",
        "                return True\n",
        "                \n",
        "            except Exception as gpu_error:\n",
        "                print(f'‚ùå GPU detected but XGBoost GPU failed: {gpu_error}')\n",
        "                print('üîÑ Falling back to CPU mode')\n",
        "                return False\n",
        "        else:\n",
        "            print('‚ö†Ô∏è  No GPU hardware detected')\n",
        "            print('üîÑ Using CPU mode')\n",
        "            return False\n",
        "            \n",
        "    except ImportError:\n",
        "        print('‚ö†Ô∏è  Not running in Google Colab - using CPU mode')\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f'‚ùå Error during GPU detection: {e}')\n",
        "        print('üîÑ Falling back to CPU mode')\n",
        "        return False\n",
        "\n",
        "# Setup GPU with safe detection\n",
        "USE_GPU = setup_gpu_safe()\n",
        "print(f'\\\\nüöÄ GPU Mode: {\"Enabled\" if USE_GPU else \"Disabled\"}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Loading and Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load preprocessed datasets\n",
        "print('Loading preprocessed datasets...')\n",
        "\n",
        "try:\n",
        "    training_data = pd.read_csv('result/training_dataset_preprocessed.csv')\n",
        "    test_data = pd.read_csv('result/test_dataset_preprocessed.csv')\n",
        "    \n",
        "    print(f'‚úÖ Training data loaded: {training_data.shape}')\n",
        "    print(f'‚úÖ Test data loaded: {test_data.shape}')\n",
        "    \n",
        "except FileNotFoundError as e:\n",
        "    print(f'‚ùå Error loading data: {e}')\n",
        "    print('Please ensure the preprocessed datasets are available in the result/ directory')\n",
        "    raise\n",
        "\n",
        "# Display basic info\n",
        "print('\\nTraining data info:')\n",
        "print(training_data.info())\n",
        "\n",
        "print('\\nTest data info:')\n",
        "print(test_data.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print('Missing values in training data:')\n",
        "missing_train = training_data.isnull().sum()\n",
        "print(missing_train[missing_train > 0])\n",
        "\n",
        "print('\\nMissing values in test data:')\n",
        "missing_test = test_data.isnull().sum()\n",
        "print(missing_test[missing_test > 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Feature Selection and Target Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define target variables\n",
        "target_variables = ['cbike_start', 'cbike_end', 'ebike_start', 'ebike_end']\n",
        "\n",
        "# Define features to exclude\n",
        "exclude_features = ['station_id', 'year', 'total_start', 'total_end']\n",
        "\n",
        "# Get feature columns (excluding targets and excluded features)\n",
        "feature_columns = [col for col in training_data.columns \n",
        "                   if col not in target_variables + exclude_features]\n",
        "\n",
        "print(f'Target variables: {target_variables}')\n",
        "print(f'Features to exclude: {exclude_features}')\n",
        "print(f'Number of feature columns: {len(feature_columns)}')\n",
        "print(f'\\nFeature columns:\\n{feature_columns}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Parameter Grid Definition (Ultra-Fast Training)\n",
        "\n",
        "‚ö° **Ultra-optimized for speed!** This parameter grid has been reduced from 2,916 to just 128 combinations for very fast training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def define_parameter_grid(use_gpu=False):\n",
        "    \"\"\"\n",
        "    Define parameter grid for XGBoost hyperparameter tuning.\n",
        "    Optimized for faster training with fewer combinations.\n",
        "    \n",
        "    Args:\n",
        "        use_gpu (bool): Whether to use GPU-optimized parameters\n",
        "    \n",
        "    Returns:\n",
        "        dict: Parameter grid for GridSearchCV\n",
        "    \"\"\"\n",
        "    # Efficient parameter grid - same for both GPU and CPU\n",
        "    # Focus on most impactful parameters with fewer options\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200],           # 2 options\n",
        "        'max_depth': [4, 6],                  # 2 options (removed 5)\n",
        "        'learning_rate': [0.05, 0.1],         # 2 options (removed 0.01)\n",
        "        'subsample': [0.8, 0.9],              # 2 options\n",
        "        'colsample_bytree': [0.8, 0.9],       # 2 options\n",
        "        'min_child_weight': [1, 3],           # 2 options (removed 5)\n",
        "        'gamma': [0, 0.1]#,                    # 2 options (removed 0.2)\n",
        "        #'reg_alpha': [0, 0.1],                # 2 options (removed 0.5)\n",
        "        #'reg_lambda': [0.1, 1.0]              # 2 options (removed 5.0)\n",
        "    }\n",
        "    \n",
        "    return param_grid\n",
        "\n",
        "# Define parameter grid based on GPU availability\n",
        "param_grid = define_parameter_grid(USE_GPU)\n",
        "print(f'Parameter grid ({'GPU' if USE_GPU else 'CPU'} mode):')\n",
        "for param, values in param_grid.items():\n",
        "    print(f'  {param}: {values}')\n",
        "\n",
        "# Calculate total combinations\n",
        "total_combinations = 1\n",
        "for values in param_grid.values():\n",
        "    total_combinations *= len(values)\n",
        "print(f'\\\\nTotal parameter combinations: {total_combinations}')\n",
        "print(f'With 5-fold CV: {total_combinations * 5} total fits')\n",
        "print(f'\\\\n‚ö° Training time: ~{total_combinations * 5 // 20}-{total_combinations * 5 // 10} minutes (estimated)')\n",
        "print(f'üöÄ Speed improvement: ~{2916 // total_combinations}x faster than original!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. XGBoost Model Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_xgboost_model(X_train, y_train, X_val, y_val, target_name, use_gpu=False):\n",
        "    \"\"\"\n",
        "    Train XGBoost model with hyperparameter tuning.\n",
        "    \n",
        "    Args:\n",
        "        X_train, y_train: Training data\n",
        "        X_val, y_val: Validation data\n",
        "        target_name (str): Name of target variable\n",
        "        use_gpu (bool): Whether to use GPU\n",
        "    \n",
        "    Returns:\n",
        "        dict: Model results and best model\n",
        "    \"\"\"\n",
        "    print(f'\\nüöÄ Training XGBoost model for {target_name}...')\n",
        "    \n",
        "    # Define base XGBoost parameters\n",
        "    base_params = {\n",
        "        'objective': 'reg:squarederror',\n",
        "        'random_state': 42,\n",
        "        'n_jobs': 1 if use_gpu else -1  # Use single thread for GPU\n",
        "    }\n",
        "    \n",
        "    if use_gpu:\n",
        "        base_params.update({\n",
        "            'tree_method': 'gpu_hist',\n",
        "            'gpu_id': 0\n",
        "        })\n",
        "    \n",
        "    # Create XGBoost regressor\n",
        "    xgb_model = xgb.XGBRegressor(**base_params)\n",
        "    \n",
        "    # Perform grid search with cross-validation\n",
        "    print('üîç Performing grid search with 5-fold cross-validation...')\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=xgb_model,\n",
        "        param_grid=param_grid,\n",
        "        cv=5,\n",
        "        scoring='r2',\n",
        "        n_jobs=1,  # Single thread for GPU compatibility\n",
        "        verbose=1\n",
        "    )\n",
        "    \n",
        "    # Fit the grid search\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    \n",
        "    # Get best model\n",
        "    best_model = grid_search.best_estimator_\n",
        "    best_params = grid_search.best_params_\n",
        "    \n",
        "    print(f'‚úÖ Best parameters: {best_params}')\n",
        "    print(f'‚úÖ Best CV score: {grid_search.best_score_:.4f}')\n",
        "    \n",
        "    # Evaluate on validation set\n",
        "    y_val_pred = best_model.predict(X_val)\n",
        "    \n",
        "    val_r2 = r2_score(y_val, y_val_pred)\n",
        "    val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
        "    val_mae = mean_absolute_error(y_val, y_val_pred)\n",
        "    \n",
        "    print(f'üìä Validation Performance:')\n",
        "    print(f'  R¬≤: {val_r2:.4f}')\n",
        "    print(f'  RMSE: {val_rmse:.4f}')\n",
        "    print(f'  MAE: {val_mae:.4f}')\n",
        "    \n",
        "    return {\n",
        "        'best_model': best_model,\n",
        "        'best_params': best_params,\n",
        "        'best_cv_score': grid_search.best_score_,\n",
        "        'val_r2': val_r2,\n",
        "        'val_rmse': val_rmse,\n",
        "        'val_mae': val_mae,\n",
        "        'grid_search': grid_search\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Model Training for All Targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for modeling\n",
        "X = training_data[feature_columns]\n",
        "print(f'Feature matrix shape: {X.shape}')\n",
        "\n",
        "# Initialize results storage\n",
        "model_results = {}\n",
        "trained_models = {}\n",
        "\n",
        "# Train models for each target variable\n",
        "for target in target_variables:\n",
        "    print(f'\\n{'='*60}')\n",
        "    print(f'TRAINING MODEL FOR: {target.upper()}')\n",
        "    print(f'{'='*60}')\n",
        "    \n",
        "    # Prepare target variable\n",
        "    y = training_data[target]\n",
        "    \n",
        "    # Split data (80% train, 20% validation)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "    \n",
        "    print(f'Training set: {X_train.shape[0]} samples')\n",
        "    print(f'Validation set: {X_val.shape[0]} samples')\n",
        "    \n",
        "    # Train model\n",
        "    results = train_xgboost_model(\n",
        "        X_train, y_train, X_val, y_val, target, USE_GPU\n",
        "    )\n",
        "    \n",
        "    # Store results\n",
        "    model_results[target] = results\n",
        "    trained_models[target] = results['best_model']\n",
        "    \n",
        "    print(f'‚úÖ Model training completed for {target}')\n",
        "\n",
        "print(f'\\nüéâ All models trained successfully!')\n",
        "print(f'Trained models: {list(trained_models.keys())}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Model Evaluation on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate models on test set\n",
        "print('\\n' + '='*60)\n",
        "print('TEST SET EVALUATION')\n",
        "print('='*60)\n",
        "\n",
        "test_results = {}\n",
        "X_test = test_data[feature_columns]\n",
        "\n",
        "for target in target_variables:\n",
        "    print(f'\\nüìä Evaluating {target} model on test set...')\n",
        "    \n",
        "    # Get true values\n",
        "    y_test = test_data[target]\n",
        "    \n",
        "    # Make predictions\n",
        "    y_test_pred = trained_models[target].predict(X_test)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    test_r2 = r2_score(y_test, y_test_pred)\n",
        "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "    \n",
        "    print(f'  Test R¬≤: {test_r2:.4f}')\n",
        "    print(f'  Test RMSE: {test_rmse:.4f}')\n",
        "    print(f'  Test MAE: {test_mae:.4f}')\n",
        "    \n",
        "    # Store test results\n",
        "    test_results[target] = {\n",
        "        'test_r2': test_r2,\n",
        "        'test_rmse': test_rmse,\n",
        "        'test_mae': test_mae,\n",
        "        'y_test': y_test,\n",
        "        'y_test_pred': y_test_pred\n",
        "    }\n",
        "\n",
        "print('\\n‚úÖ Test set evaluation completed!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Results Summary and Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive results summary\n",
        "print('\\n' + '='*80)\n",
        "print('COMPREHENSIVE MODEL PERFORMANCE SUMMARY')\n",
        "print('='*80)\n",
        "\n",
        "summary_data = []\n",
        "\n",
        "for target in target_variables:\n",
        "    # Training/validation results\n",
        "    train_results = model_results[target]\n",
        "    \n",
        "    # Test results\n",
        "    test_results_target = test_results[target]\n",
        "    \n",
        "    # Create summary row\n",
        "    summary_row = {\n",
        "        'Target': target,\n",
        "        'Best_CV_Score': train_results['best_cv_score'],\n",
        "        'Val_R2': train_results['val_r2'],\n",
        "        'Val_RMSE': train_results['val_rmse'],\n",
        "        'Val_MAE': train_results['val_mae'],\n",
        "        'Test_R2': test_results_target['test_r2'],\n",
        "        'Test_RMSE': test_results_target['test_rmse'],\n",
        "        'Test_MAE': test_results_target['test_mae']\n",
        "    }\n",
        "    \n",
        "    summary_data.append(summary_row)\n",
        "    \n",
        "    # Print detailed results\n",
        "    print(f'\\nüéØ {target.upper()}:')\n",
        "    print(f'  Best CV Score: {train_results['best_cv_score']:.4f}')\n",
        "    print(f'  Validation - R¬≤: {train_results['val_r2']:.4f}, RMSE: {train_results['val_rmse']:.4f}, MAE: {train_results['val_mae']:.4f}')\n",
        "    print(f'  Test      - R¬≤: {test_results_target['test_r2']:.4f}, RMSE: {test_results_target['test_rmse']:.4f}, MAE: {test_results_target['test_mae']:.4f}')\n",
        "    print(f'  Best Parameters: {train_results['best_params']}')\n",
        "\n",
        "# Create summary DataFrame\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "print('\\nüìä Performance Summary Table:')\n",
        "print(summary_df.round(4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Feature Importance Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze feature importance for each model\n",
        "print('\\n' + '='*60)\n",
        "print('FEATURE IMPORTANCE ANALYSIS')\n",
        "print('='*60)\n",
        "\n",
        "for target in target_variables:\n",
        "    print(f'\\nüîç Feature importance for {target} model:')\n",
        "    \n",
        "    model = trained_models[target]\n",
        "    \n",
        "    # Get feature importance\n",
        "    importance_df = pd.DataFrame({\n",
        "        'feature': feature_columns,\n",
        "        'importance': model.feature_importances_\n",
        "    })\n",
        "    \n",
        "    # Sort by importance\n",
        "    importance_df = importance_df.sort_values('importance', ascending=False)\n",
        "    \n",
        "    # Display top 15 features\n",
        "    print(f'Top 15 most important features:')\n",
        "    print(importance_df.head(15).round(4))\n",
        "    \n",
        "    # Plot feature importance\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    top_features = importance_df.head(20)\n",
        "    \n",
        "    plt.barh(range(len(top_features)), top_features['importance'])\n",
        "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
        "    plt.xlabel('Feature Importance')\n",
        "    plt.title(f'Top 20 Feature Importance - {target}')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Model Performance Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create performance comparison plots\n",
        "print('\\nüìà Creating performance visualization...')\n",
        "\n",
        "# R¬≤ comparison\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle('Model Performance Comparison', fontsize=16)\n",
        "\n",
        "metrics = ['R¬≤', 'RMSE', 'MAE']\n",
        "metric_cols = ['r2', 'rmse', 'mae']\n",
        "\n",
        "for i, (metric, col) in enumerate(zip(metrics, metric_cols)):\n",
        "    ax = axes[i//2, i%2]\n",
        "    \n",
        "    # Prepare data for plotting\n",
        "    val_data = [model_results[target][f'val_{col}'] for target in target_variables]\n",
        "    test_data = [test_results[target][f'test_{col}'] for target in target_variables]\n",
        "    \n",
        "    x = np.arange(len(target_variables))\n",
        "    width = 0.35\n",
        "    \n",
        "    ax.bar(x - width/2, val_data, width, label='Validation', alpha=0.8)\n",
        "    ax.bar(x + width/2, test_data, width, label='Test', alpha=0.8)\n",
        "    \n",
        "    ax.set_xlabel('Target Variable')\n",
        "    ax.set_Google Colab\n",
        "    ax.set_title(f'{metric} Comparison')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(target_variables, rotation=45)\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Actual vs Predicted plots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle('Actual vs Predicted Values (Test Set)', fontsize=16)\n",
        "\n",
        "for i, target in enumerate(target_variables):\n",
        "    ax = axes[i//2, i%2]\n",
        "    \n",
        "    y_true = test_results[target]['y_test']\n",
        "    y_pred = test_results[target]['y_test_pred']\n",
        "    \n",
        "    ax.scatter(y_true, y_pred, alpha=0.6)\n",
        "    ax.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)\n",
        "    \n",
        "    ax.set_xlabel('Actual Values')\n",
        "    ax.set_ylabel('Predicted Values')\n",
        "    ax.set_title(f'{target} - R¬≤: {test_results[target][\"test_r2\"]:.4f}')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Save Results and Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save results to CSV\n",
        "print('\\nüíæ Saving results...')\n",
        "\n",
        "# Prepare results for saving\n",
        "results_data = []\n",
        "for target in target_variables:\n",
        "    train_results = model_results[target]\n",
        "    test_results_target = test_results[target]\n",
        "    \n",
        "    row = {\n",
        "        'target_variable': target,\n",
        "        'best_cv_score': train_results['best_cv_score'],\n",
        "        'validation_r2': train_results['val_r2'],\n",
        "        'validation_rmse': train_results['val_rmse'],\n",
        "        'validation_mae': train_results['val_mae'],\n",
        "        'test_r2': test_results_target['test_r2'],\n",
        "        'test_rmse': test_results_target['test_rmse'],\n",
        "        'test_mae': test_results_target['test_mae'],\n",
        "        'best_parameters': str(train_results['best_params']),\n",
        "        'gpu_used': USE_GPU\n",
        "    }\n",
        "    results_data.append(row)\n",
        "\n",
        "# Create and save results DataFrame\n",
        "results_df = pd.DataFrame(results_data)\n",
        "results_df.to_csv('result/xgboost_results.csv', index=False)\n",
        "print(f'‚úÖ Results saved to result/xgboost_results.csv')\n",
        "\n",
        "# Save models (optional - for future use)\n",
        "import joblib\n",
        "for target in target_variables:\n",
        "    model_filename = f'result/xgboost_model_{target}.joblib'\n",
        "    joblib.dump(trained_models[target], model_filename)\n",
        "    print(f'‚úÖ Model saved to {model_filename}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Summary and Next Steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('\\n' + '='*80)\n",
        "print('üéâ XGBOOST MODELING COMPLETED SUCCESSFULLY!')\n",
        "print('='*80)\n",
        "\n",
        "print(f'\\nüìä Models Trained: {len(trained_models)}')\n",
        "print(f'üéØ Target Variables: {', '.join(target_variables)}')\n",
        "print(f'üöÄ GPU Acceleration: {'Enabled' if USE_GPU else 'Disabled'}')\n",
        "print(f'üîç Features Used: {len(feature_columns)}')\n",
        "\n",
        "print('\\nüìÅ Files Generated:')\n",
        "print('  - result/xgboost_results.csv (performance metrics)')\n",
        "print('  - result/xgboost_model_*.joblib (trained models)')\n",
        "\n",
        "print('\\nüöÄ Next Steps:')\n",
        "print('  1. Analyze feature importance for insights')\n",
        "print('  2. Compare with linear regression results')\n",
        "print('  3. Consider ensemble methods')\n",
        "print('  4. Deploy models for predictions')\n",
        "\n",
        "print('\\n‚úÖ Notebook execution completed!')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
